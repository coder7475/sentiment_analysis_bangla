{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 5: Evaluation and Comparison\n",
    "\n",
    "**Objective**: Compare baseline models (Phase 3) and mitigated models (Phase 4) to assess the effectiveness of imbalance mitigation strategies (SMOTE, Random Undersampling, NearMiss, Weighted Loss) for 3-class (Negative, Neutral, Positive) sentiment classification on the Bangla Sentiment Dataset. Evaluate performance on the test set, analyze source-specific performance (newspapers, social media, blogs) to test hypothesis H3 (source-specific differences in sentiment classification), and perform statistical tests to determine significant improvements.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Load Test Data and Models\n",
    "\n",
    "- **Objective**: Load test TF-IDF matrix, labels, source metadata, and all models (baseline and mitigated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-25 10:56:14,740 - INFO - Test data loaded successfully\n",
      "2025-06-25 10:56:14,742 - INFO - Data shapes validated\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "import joblib\n",
    "import os\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Define paths\n",
    "data_dir = \"text_representation/\"\n",
    "\n",
    "files = {\n",
    "    'tfidf_test': f\"{data_dir}tfidf_test.npz\",\n",
    "    'labels_test': f\"{data_dir}labels_test.csv\",\n",
    "}\n",
    "\n",
    "# Check file existence\n",
    "for name, path in files.items():\n",
    "    if not os.path.exists(path):\n",
    "        logging.error(f\"Missing file: {path}\")\n",
    "        raise FileNotFoundError(f\"Missing file: {path}\")\n",
    "\n",
    "# Load test data\n",
    "tfidf_test = sp.load_npz(files['tfidf_test'])\n",
    "y_test = pd.read_csv(files['labels_test'], encoding='utf-8')['Label'].values\n",
    "\n",
    "logging.info(\"Test data loaded successfully\")\n",
    "\n",
    "# Validate shapes\n",
    "assert tfidf_test.shape[0] == len(y_test), \"Test data mismatch\"\n",
    "logging.info(\"Data shapes validated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading baseline models:   0%|          | 0/4 [00:00<?, ?it/s]/home/fahad/projects/personal/sentiment_analysis_bangla/venv/lib/python3.11/site-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator LogisticRegression from version 1.7.0 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "2025-06-25 10:58:40,317 - INFO - Loaded model: baseline_LogisticRegression_tuned_grid\n",
      "Loading baseline models:  25%|██▌       | 1/4 [00:01<00:05,  1.78s/it]/home/fahad/projects/personal/sentiment_analysis_bangla/venv/lib/python3.11/site-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator SVC from version 1.7.0 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "2025-06-25 10:58:40,338 - INFO - Loaded model: baseline_SVM_tuned_grid\n",
      "/home/fahad/projects/personal/sentiment_analysis_bangla/venv/lib/python3.11/site-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator MultinomialNB from version 1.7.0 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "2025-06-25 10:58:40,352 - INFO - Loaded model: baseline_NaiveBayes_tuned_grid\n",
      "/home/fahad/projects/personal/sentiment_analysis_bangla/venv/lib/python3.11/site-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.7.0 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/home/fahad/projects/personal/sentiment_analysis_bangla/venv/lib/python3.11/site-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator RandomForestClassifier from version 1.7.0 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "2025-06-25 10:58:41,359 - INFO - Loaded model: baseline_RandomForest_tuned_grid\n",
      "Loading baseline models: 100%|██████████| 4/4 [00:02<00:00,  1.42it/s]\n",
      "Loading mitigated models:   0%|          | 0/16 [00:00<?, ?it/s]2025-06-25 10:58:41,373 - INFO - Loaded model: mitigated_LogisticRegression_smote_tuned\n",
      "2025-06-25 10:58:41,378 - INFO - Loaded model: mitigated_LogisticRegression_undersampled_tuned\n",
      "2025-06-25 10:58:41,383 - INFO - Loaded model: mitigated_LogisticRegression_nearmiss_tuned\n",
      "2025-06-25 10:58:41,389 - INFO - Loaded model: mitigated_LogisticRegression_weighted_tuned\n",
      "2025-06-25 10:58:41,402 - INFO - Loaded model: mitigated_SVM_smote_tuned\n",
      "2025-06-25 10:58:41,414 - INFO - Loaded model: mitigated_SVM_undersampled_tuned\n",
      "2025-06-25 10:58:41,427 - INFO - Loaded model: mitigated_SVM_nearmiss_tuned\n",
      "2025-06-25 10:58:41,445 - INFO - Loaded model: mitigated_SVM_weighted_tuned\n",
      "2025-06-25 10:58:41,451 - INFO - Loaded model: mitigated_NaiveBayes_smote_tuned\n",
      "2025-06-25 10:58:41,462 - INFO - Loaded model: mitigated_NaiveBayes_undersampled_tuned\n",
      "2025-06-25 10:58:41,468 - INFO - Loaded model: mitigated_NaiveBayes_nearmiss_tuned\n",
      "Loading mitigated models:  69%|██████▉   | 11/16 [00:00<00:00, 109.33it/s]2025-06-25 10:58:41,479 - INFO - Loaded model: mitigated_NaiveBayes_weighted_tuned\n",
      "2025-06-25 10:58:42,249 - INFO - Loaded model: mitigated_RandomForest_smote_tuned\n",
      "2025-06-25 10:58:42,428 - INFO - Loaded model: mitigated_RandomForest_undersampled_tuned\n",
      "2025-06-25 10:58:42,580 - INFO - Loaded model: mitigated_RandomForest_nearmiss_tuned\n",
      "2025-06-25 10:58:43,520 - INFO - Loaded model: mitigated_RandomForest_weighted_tuned\n",
      "Loading mitigated models: 100%|██████████| 16/16 [00:02<00:00,  7.44it/s] \n"
     ]
    }
   ],
   "source": [
    "# Load models\n",
    "model_dir_baseline = \"models/baseline_models/\"\n",
    "model_dir_mitigated = \"models/mitigated_models/\"\n",
    "\n",
    "model_configs = [\n",
    "    ('baseline', model_dir_baseline, ['LogisticRegression_tuned_grid', 'SVM_tuned_grid', 'NaiveBayes_tuned_grid', 'RandomForest_tuned_grid']),\n",
    "    ('mitigated', model_dir_mitigated, [\n",
    "        f\"{model}_{mitigation}_tuned\"\n",
    "        for model in ['LogisticRegression', 'SVM', 'NaiveBayes', 'RandomForest']\n",
    "        for mitigation in ['smote', 'undersampled', 'nearmiss', 'weighted']\n",
    "    ])\n",
    "]\n",
    "models = {}\n",
    "for config_type, model_dir, model_names in model_configs:\n",
    "    for name in tqdm(model_names, desc=f\"Loading {config_type} models\"):\n",
    "        try:\n",
    "            models[f\"{config_type}_{name}\"] = joblib.load(f\"{model_dir}{name}.joblib\")\n",
    "            logging.info(f\"Loaded model: {config_type}_{name}\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error loading {name}: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Evaluate Models on Test Set\n",
    "\n",
    "- **Objective**: Compute accuracy, precision, recall, F1-score (weighted and per-class), and ROC-AUC for all models on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating models:   0%|          | 0/20 [00:00<?, ?it/s]2025-06-25 11:05:26,289 - INFO - Evaluated baseline_LogisticRegression_tuned_grid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-25 11:05:31,714 - INFO - Evaluated baseline_SVM_tuned_grid\n",
      "Evaluating models:  10%|█         | 2/20 [00:05<00:49,  2.73s/it]2025-06-25 11:05:31,736 - INFO - Evaluated baseline_NaiveBayes_tuned_grid\n",
      "2025-06-25 11:05:32,233 - INFO - Evaluated baseline_RandomForest_tuned_grid\n",
      "Evaluating models:  20%|██        | 4/20 [00:05<00:20,  1.27s/it]2025-06-25 11:05:32,248 - INFO - Evaluated mitigated_LogisticRegression_smote_tuned\n",
      "2025-06-25 11:05:32,264 - INFO - Evaluated mitigated_LogisticRegression_undersampled_tuned\n",
      "2025-06-25 11:05:32,280 - INFO - Evaluated mitigated_LogisticRegression_nearmiss_tuned\n",
      "2025-06-25 11:05:32,296 - INFO - Evaluated mitigated_LogisticRegression_weighted_tuned\n",
      "2025-06-25 11:05:34,653 - INFO - Evaluated mitigated_SVM_smote_tuned\n",
      "Evaluating models:  45%|████▌     | 9/20 [00:08<00:08,  1.35it/s]2025-06-25 11:05:36,354 - INFO - Evaluated mitigated_SVM_undersampled_tuned\n",
      "Evaluating models:  50%|█████     | 10/20 [00:10<00:08,  1.12it/s]2025-06-25 11:05:37,947 - INFO - Evaluated mitigated_SVM_nearmiss_tuned\n",
      "Evaluating models:  55%|█████▌    | 11/20 [00:11<00:09,  1.03s/it]2025-06-25 11:05:40,076 - INFO - Evaluated mitigated_SVM_weighted_tuned\n",
      "Evaluating models:  60%|██████    | 12/20 [00:13<00:10,  1.26s/it]2025-06-25 11:05:40,098 - INFO - Evaluated mitigated_NaiveBayes_smote_tuned\n",
      "2025-06-25 11:05:40,127 - INFO - Evaluated mitigated_NaiveBayes_undersampled_tuned\n",
      "2025-06-25 11:05:40,154 - INFO - Evaluated mitigated_NaiveBayes_nearmiss_tuned\n",
      "2025-06-25 11:05:40,185 - INFO - Evaluated mitigated_NaiveBayes_weighted_tuned\n",
      "Evaluating models:  80%|████████  | 16/20 [00:13<00:02,  1.71it/s]2025-06-25 11:05:40,593 - INFO - Evaluated mitigated_RandomForest_smote_tuned\n",
      "2025-06-25 11:05:40,753 - INFO - Evaluated mitigated_RandomForest_undersampled_tuned\n",
      "Evaluating models:  90%|█████████ | 18/20 [00:14<00:01,  2.00it/s]2025-06-25 11:05:40,928 - INFO - Evaluated mitigated_RandomForest_nearmiss_tuned\n",
      "Evaluating models:  95%|█████████▌| 19/20 [00:14<00:00,  2.24it/s]2025-06-25 11:05:41,321 - INFO - Evaluated mitigated_RandomForest_weighted_tuned\n",
      "Evaluating models: 100%|██████████| 20/20 [00:15<00:00,  1.33it/s]\n",
      "2025-06-25 11:05:41,332 - INFO - Comparative results saved: evaluation/comparative_results.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Ensure evaluation directory exists\n",
    "os.makedirs(\"evaluation\", exist_ok=True)\n",
    "\n",
    "# Binarize labels for ROC AUC\n",
    "lb = LabelBinarizer()\n",
    "y_test_bin = lb.fit_transform(y_test)\n",
    "\n",
    "results = {\n",
    "    'Model': [], 'Type': [], 'Mitigation': [],\n",
    "    'Accuracy': [], 'F1_Weighted': [], 'F1_Negative': [], \n",
    "    'F1_Positive': [], 'F1_Neutral': [], 'ROC_AUC': []\n",
    "}\n",
    "\n",
    "for model_key, model in tqdm(models.items(), desc=\"Evaluating models\"):\n",
    "    try:\n",
    "        config_type, name = model_key.split('_', 1)\n",
    "        mitigation = name.split('_')[-1] if config_type == 'mitigated' else 'none'\n",
    "        model_name = '_'.join(name.split('_')[:-1]) if config_type == 'mitigated' else name.replace('_tuned_grid', '')\n",
    "\n",
    "        y_pred = model.predict(tfidf_test)\n",
    "        y_pred_proba = model.predict_proba(tfidf_test)\n",
    "        \n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred, average='weighted')\n",
    "        f1_per_class = precision_recall_fscore_support(y_test, y_pred)[2]\n",
    "        roc_auc = roc_auc_score(y_test_bin, y_pred_proba, multi_class='ovr')\n",
    "\n",
    "        results['Model'].append(model_name)\n",
    "        results['Type'].append(config_type)\n",
    "        results['Mitigation'].append(mitigation)\n",
    "        results['Accuracy'].append(accuracy_score(y_test, y_pred))\n",
    "        results['F1_Weighted'].append(f1)\n",
    "        results['F1_Negative'].append(f1_per_class[0])\n",
    "        results['F1_Positive'].append(f1_per_class[1])\n",
    "        results['F1_Neutral'].append(f1_per_class[2])\n",
    "        results['ROC_AUC'].append(roc_auc)\n",
    "\n",
    "        logging.info(f\"Evaluated {model_key}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error evaluating {model_key}: {str(e)}\")\n",
    "\n",
    "# Save and show results\n",
    "results_df = pd.DataFrame(results)\n",
    "csv_path = \"evaluation/comparative_results.csv\"\n",
    "results_df.to_csv(csv_path, index=False)\n",
    "logging.info(f\"Comparative results saved: {csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Evaluation Results ===\n",
      "\n",
      "| Model                           | Type      | Mitigation   |   Accuracy |   F1_Weighted |   F1_Negative |   F1_Positive |   F1_Neutral |   ROC_AUC |\n",
      "|---------------------------------|-----------|--------------|------------|---------------|---------------|---------------|--------------|-----------|\n",
      "| LogisticRegression              | baseline  | none         |   0.629677 |      0.612208 |      0.715596 |      0.521739 |     0.51715  |  0.753958 |\n",
      "| SVM                             | baseline  | none         |   0.625806 |      0.612925 |      0.707692 |      0.530351 |     0.52551  |  0.734816 |\n",
      "| NaiveBayes                      | baseline  | none         |   0.621935 |      0.595792 |      0.710098 |      0.503597 |     0.48433  |  0.744348 |\n",
      "| RandomForest                    | baseline  | none         |   0.618065 |      0.593155 |      0.711602 |      0.478571 |     0.493151 |  0.743115 |\n",
      "| LogisticRegression_smote        | mitigated | tuned        |   0.574194 |      0.574455 |      0.648427 |      0.50411  |     0.511013 |  0.73087  |\n",
      "| LogisticRegression_undersampled | mitigated | tuned        |   0.593548 |      0.591833 |      0.656992 |      0.524064 |     0.54067  |  0.736189 |\n",
      "| LogisticRegression_nearmiss     | mitigated | tuned        |   0.56129  |      0.562888 |      0.612536 |      0.5      |     0.533058 |  0.720751 |\n",
      "| LogisticRegression_weighted     | mitigated | tuned        |   0.550968 |      0.553486 |      0.622159 |      0.480211 |     0.501071 |  0.707145 |\n",
      "| SVM_smote                       | mitigated | tuned        |   0.624516 |      0.610252 |      0.710588 |      0.520635 |     0.519481 |  0.731085 |\n",
      "| SVM_undersampled                | mitigated | tuned        |   0.621935 |      0.618953 |      0.690013 |      0.539945 |     0.567308 |  0.740134 |\n",
      "| SVM_nearmiss                    | mitigated | tuned        |   0.567742 |      0.568971 |      0.625    |      0.531073 |     0.508403 |  0.726973 |\n",
      "| SVM_weighted                    | mitigated | tuned        |   0.615484 |      0.602466 |      0.699052 |      0.518987 |     0.512821 |  0.730338 |\n",
      "| NaiveBayes_smote                | mitigated | tuned        |   0.549677 |      0.544981 |      0.631579 |      0.474777 |     0.460829 |  0.709405 |\n",
      "| NaiveBayes_undersampled         | mitigated | tuned        |   0.587097 |      0.586943 |      0.640434 |      0.523161 |     0.55157  |  0.739679 |\n",
      "| NaiveBayes_nearmiss             | mitigated | tuned        |   0.584516 |      0.58204  |      0.644068 |      0.52819  |     0.524664 |  0.726909 |\n",
      "| NaiveBayes_weighted             | mitigated | tuned        |   0.549677 |      0.544981 |      0.631579 |      0.474777 |     0.460829 |  0.709405 |\n",
      "| RandomForest_smote              | mitigated | tuned        |   0.596129 |      0.583424 |      0.684211 |      0.483871 |     0.5      |  0.731342 |\n",
      "| RandomForest_undersampled       | mitigated | tuned        |   0.616774 |      0.613338 |      0.684755 |      0.544444 |     0.552885 |  0.735062 |\n",
      "| RandomForest_nearmiss           | mitigated | tuned        |   0.552258 |      0.553687 |      0.596888 |      0.513228 |     0.516129 |  0.718303 |\n",
      "| RandomForest_weighted           | mitigated | tuned        |   0.596129 |      0.583424 |      0.684211 |      0.483871 |     0.5      |  0.731342 |\n"
     ]
    }
   ],
   "source": [
    "# Display as table in notebook output\n",
    "from IPython.display import display, HTML\n",
    "print(\"\\n=== Evaluation Results ===\\n\")\n",
    "print(tabulate(results_df, headers='keys', tablefmt='github', showindex=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
